% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pilot_train.R
\name{pilot_train}
\alias{pilot_train}
\title{Training the data directly}
\usage{
pilot_train(x_train, y_train, x_test, method = c("svm", "randomforest"))
}
\arguments{
\item{x_train}{input variables of training data}

\item{y_train}{labels of training data}

\item{x_test}{input variables of test data}

\item{method}{base classification method.
\itemize{
\item logistic: Logistic regression. \link{glm} function with family = 'binomial'
\item penlog: Penalized logistic regression with LASSO penalty. \code{\link[glmnet]{glmnet}} in \code{glmnet} package
\item svm: Support Vector Machines. \code{\link[e1071]{svm}} in \code{e1071} package
\item randomforest: Random Forest. \code{\link[randomForest]{randomForest}} in \code{randomForest} package
\item lda: Linear Discriminant Analysis. \code{\link[MASS]{lda}} in \code{MASS} package
\item slda: Sparse Linear Discriminant Analysis with LASSO penalty.
\item nb: Naive Bayes. \code{\link[e1071]{naiveBayes}} in \code{e1071} package
\item nnb: Nonparametric Naive Bayes. \code{\link[naivebayes]{naive_bayes}} in \code{naivebayes} package
\item ada: Ada-Boost. \code{\link[ada]{ada}} in \code{ada} package
\item xgboost: XGBboost. \code{\link[xgboost]{xgboost}} in \code{xgboost} package
\item tree: Classificatin Tree. \code{\link[tree]{tree}} in \code{tree} package
}}
}
\value{
the scores predicted by Logistic Regresion, Random Forrest, Support Vector Machine and Xgboost seperately
}
\description{
use different methods to train the data.
}
\examples{

library(mvtnorm)
library(MASS)

df = 10
rho = 0.5
d = 5
delta = rep(2, d)
H <- abs(outer(1:d, 1:d, "-"))
covxx = rho^H

n1_all <- n0_all <- 800
n1_train <- n0_train <- n_train <- 60
n0_test <- n1_test <- 300

x0_all = rmvt(n = n0_all, sigma = covxx, delta = rep(0, d), df = df)
x1_all = rmvt(n = n1_all, sigma = covxx, delta = delta, df = df)

x_data = rbind(x0_all, x1_all)
y_data = c(rep(0, n0_all), rep(1, n1_all))

id0 <- which(y_data == 0)
id1 <- which(y_data == 1)

id0_train <- sample(id0, n0_train)
id1_train <- sample(id1, n1_train)
id_train <- c(id0_train, id1_train)
x_train <- as.matrix(x_data[id_train, ])
y_train <- as.matrix(y_data[id_train])

id0_remain = setdiff(id0, id0_train)
id1_remain = setdiff(id1, id1_train)

id0_test <- sample(id0_remain, n0_test)
id1_test <- sample(id1_remain, n1_test)
id_test <- c(id0_test, id1_test)
x_test <- as.matrix(x_data[id_test, ])

result = pilot_train(x_train, y_train, x_test, method = c("svm", "randomforest"))
}
