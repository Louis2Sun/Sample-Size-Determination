class(data_example)
x_pilot_df = data.frame(x_pilot)
y_pilot_df = data.frame(y_pilot)
pilot_df = cbind(x_pilot_df,y_pilot_df)
table(pilot_df$y_pilot)
newData <- SMOTE(pilot_df[,-6], pilot_df[,6],K=5, dup_size = 2)
id0_p = which(y_pilot==0)
id1_p = which(y_pilot==1)
n0_p = length(id0_p)
n1_p = length(id1_p)
n0_tt = n0_train + n0_test
n1_tt = n1_train + n1_test
x_pilot_df = data.frame(x_pilot)
y_pilot_df = data.frame(y_pilot)
pilot_df = cbind(x_pilot_df,y_pilot_df)
# pilot_df$y_pilot = as.factor(pilot_df$y_pilot)
table(pilot_df$y_pilot)
n_min_p = min(n0_p,n1_p)
n_min_tt = min(n0_tt,n1_tt)
# a = ceiling(n_min_tt/n_min_p-1)*100
# b = ceiling(1e4*n_max_tt/a/n_min_p)
label_col_num = grep("y_pilot",colnames(newData))
newData <- SMOTE(pilot_df[,-label_col_num], pilot_df[,label_col_num],K=5, dup_size = ceiling(n_min_tt/n_min_p))
label_col_num
df))
# a = ceiling(n_min_tt/n_min_p-1)*100
# b = ceiling(1e4*n_max_tt/a/n_min_p)
label_col_num = grep("y_pilot",colnames(pilot_df))
label_col_num
newData <- SMOTE(pilot_df[,-label_col_num], pilot_df[,label_col_num], K=5, dup_size = ceiling(n_min_tt/n_min_p))
View(newData)
View(newData)
n_min_tt
View(newData)
View(newData)
newData[["data"]]
newData[["syn_data"]]
newData[["syn_data"]][["class"]]
newData[["data"]][["class"]]
newData[["data"]]
newData2 <- SMOTE(newData[["data"]][,-label_col_num], newData[["data"]][,label_col_num], K=5, dup_size = ceiling(n_max_tt/n_min_p))
# n_min_tt = min(n0_tt,n1_tt)
n_max_tt = max(n0_tt,n1_tt)
newData <- SMOTE(pilot_df[,-label_col_num], pilot_df[,label_col_num], K=5, dup_size = ceiling(n_max_tt/n_min_p))
newData2 <- SMOTE(newData[["data"]][,-label_col_num], newData[["data"]][,label_col_num], K=5, dup_size = ceiling(n_max_tt/n_min_p))
View(newData2)
View(newData2)
table(newData2[["data"]][["class"]])
tempData1 <- SMOTE(pilot_df[,-label_col_num], pilot_df[,label_col_num], K=5, dup_size = ceiling(n_max_tt/n_min_p))
tempData2 <- SMOTE(tempData1[["data"]][,-label_col_num], tempData1[["data"]][,label_col_num], K=5, dup_size = ceiling(n_max_tt/n_min_p))
# newData <- SMOTE(y_pilot ~ ., pilot_df, perc.over = a, perc.under=b)
newData = tempData2[["data"]]
View(newData)
View(newData)
table(newData$class)
id0 <- which(newData["class"]==0)
id1 <- which(newData["class"]==1)
###train
id0_train <- sample(id0,n0_train)
id1_train <- sample(id1,n1_train)
id_train <- c(id0_train,id1_train)
x_train <- as.matrix(newData[,-grep("y_pilot",colnames(newData))][id_train,])
y_train <- as.matrix(newData[,"y_pilot"][id_train])
train_x=as.data.frame(x_train)
###train
id0_train <- sample(id0,n0_train)
id1_train <- sample(id1,n1_train)
id_train <- c(id0_train,id1_train)
x_train <- as.matrix(newData[,-grep("class",colnames(newData))][id_train,])
y_train <- as.matrix(newData[,"class"][id_train])
train_x=as.data.frame(x_train)
train_y=y_train
data_trainxy<-data.frame(train_x,y_train)
###test
id0_remain = setdiff(id0,id0_train)
id1_remain = setdiff(id1,id1_train)
id0_test <- sample(id0_remain,n0_test)
id1_test <- sample(id1_remain,n1_test)
id_test <- c(id0_test,id1_test)
x_test <- as.matrix(newData[,-grep("class",colnames(newData))][id_test,])
y_test <- as.matrix(newData[,"class"][id_test])
test_x=as.data.frame(x_test)
method="svm"
methods_all = c("logistic", "penlog", "svm", "randomforest", "lda", "slda", "nb", "nnb", "ada", "tree","xgboost","self")
p_results = numeric()
# print(method)
for (i in 1:length(method)){
# print(method[i])
if(!method[i] %in% methods_all){
stop('method \'',method[i], '\' cannot be found')
}
###LR
if(method[i] == "logistic"){
fit_LR<-suppressWarnings(glm(train_y~.,family = "binomial",data=data_trainxy, maxit=100))
prep_LR<-predict(fit_LR,test_x)
p_LR<-1/(1+exp(-prep_LR))
p_results=rbind(p_results,p_LR)
}
###xgboost
if(method[i] == "xgboost"){
new_trainx<-as.matrix(train_x)
dx_trainy<-xgb.DMatrix(data = new_trainx, label = train_y)
fit_xgb <- xgboost(data=dx_trainy, nthread=3,nrounds=100,objective = "binary:logistic", verbose = 0)
p_xgb<-predict(fit_xgb,as.matrix(test_x))
p_results=rbind(p_results,p_xgb)
}
###SVM
if(method[i] == "svm"){
data_trainxy<-data.frame(train_x,train_y=as.factor(train_y))
fit_svm<-svm(train_y~.,data=data_trainxy,probability=TRUE)
pred_svm <- predict(fit_svm, test_x, probability=TRUE,decision.values = TRUE)
p_svm=as.data.frame(attr(pred_svm, "probabilities"))$"1"
p_results=rbind(p_results,p_svm)
}
###RF
if(method[i] == "randomforest"){
data_trainxy<-data.frame(train_x,train_y=as.factor(train_y))
fit_RF<-randomForest(train_y~.,data = data_trainxy,importance=TRUE)
p_RF=predict(fit_RF,test_x,type = "prob")[, 2]
p_results=rbind(p_results,p_RF)
}
###Penalized logistic regression with LASSO penalty
if(method[i] == "penlog"){
fit_penlog = cv.glmnet(as.matrix(train_x), train_y, family = "binomial")
p_penlog = t(predict(fit_penlog$glmnet.fit, newx = as.matrix(test_x), type = "response", s = fit_penlog$lambda.min))
rownames(p_penlog)="p_penlog"
p_results=rbind(p_results,p_penlog)
}
###Linear Discriminant Analysis
if(method[i] == "lda"){
fit_lda = lda(as.matrix(train_x), train_y)
p_lda = predict(fit_lda, as.matrix(test_x))$posterior[, 2]
p_results=rbind(p_results,p_lda)
}
###Sparse Linear Discriminant Analysis with LASSO penalty
if(method[i] == "slda"){
n1 = sum(train_y==1)
n0 = sum(train_y==0)
n = n1 + n0
y_lda = train_y
y_lda[train_y == 0] = -n/n0
y_lda[train_y == 1] = n/n1
fit_slda = cv.glmnet(as.matrix(train_x), y_lda)
score_slda = t(predict(fit_slda$glmnet.fit, newx = as.matrix(test_x), type = "link", s = fit_slda$lambda.min))
p_slda = 1/(1+exp(-score_slda))
rownames(p_slda)="p_slda"
p_results=rbind(p_results,p_slda)
}
###Naive Bayes
if(method[i] == "nb"){
train_data_nb = data.frame(train_x, y = train_y)
fit_nb <- naive_bayes(as.factor(y) ~ ., data = train_data_nb, usekernel = FALSE)
p_nb = predict(fit_nb, data.frame(test_x), type = "prob")[,2]
p_results=rbind(p_results,p_nb)
}
###Nonparametric Naive Bayes
if(method[i] == "nnb"){
train_data_nnb = data.frame(train_x, y = train_y)
fit_nnb <- naive_bayes(as.factor(y) ~ ., data = train_data_nnb, usekernel = TRUE)
p_nnb = predict(fit_nnb, data.frame(test_x), type = "prob")[,2]
p_results=rbind(p_results,p_nnb)
}
###Ada-Boost
if(method[i] == "ada"){
train_data_ada = data.frame(train_x, y = train_y)
fit_ada = ada(y ~ ., data = train_data_ada)
p_ada = predict(fit_ada, data.frame(test_x), type = "probs")[, 2]
p_results=rbind(p_results,p_ada)
}
###Classification
if(method[i] == "tree"){
# train_y = as.factor(train_y)
train_data_tree = data.frame(train_x, y = train_y)
fit_tree = tree(y~ ., data = train_data_tree)
p_tree = predict(fit_tree, newdata = data.frame(test_x), type = 'vector')
p_results=rbind(p_results,p_tree)
}
###Self-defined
if(method[i] == "self"){
p_self = func(train_x, train_y, test_x)
p_results=rbind(p_results,p_self)
}
}
require(e1071)
# print(method)
for (i in 1:length(method)){
# print(method[i])
if(!method[i] %in% methods_all){
stop('method \'',method[i], '\' cannot be found')
}
###LR
if(method[i] == "logistic"){
fit_LR<-suppressWarnings(glm(train_y~.,family = "binomial",data=data_trainxy, maxit=100))
prep_LR<-predict(fit_LR,test_x)
p_LR<-1/(1+exp(-prep_LR))
p_results=rbind(p_results,p_LR)
}
###xgboost
if(method[i] == "xgboost"){
new_trainx<-as.matrix(train_x)
dx_trainy<-xgb.DMatrix(data = new_trainx, label = train_y)
fit_xgb <- xgboost(data=dx_trainy, nthread=3,nrounds=100,objective = "binary:logistic", verbose = 0)
p_xgb<-predict(fit_xgb,as.matrix(test_x))
p_results=rbind(p_results,p_xgb)
}
###SVM
if(method[i] == "svm"){
data_trainxy<-data.frame(train_x,train_y=as.factor(train_y))
fit_svm<-svm(train_y~.,data=data_trainxy,probability=TRUE)
pred_svm <- predict(fit_svm, test_x, probability=TRUE,decision.values = TRUE)
p_svm=as.data.frame(attr(pred_svm, "probabilities"))$"1"
p_results=rbind(p_results,p_svm)
}
###RF
if(method[i] == "randomforest"){
data_trainxy<-data.frame(train_x,train_y=as.factor(train_y))
fit_RF<-randomForest(train_y~.,data = data_trainxy,importance=TRUE)
p_RF=predict(fit_RF,test_x,type = "prob")[, 2]
p_results=rbind(p_results,p_RF)
}
###Penalized logistic regression with LASSO penalty
if(method[i] == "penlog"){
fit_penlog = cv.glmnet(as.matrix(train_x), train_y, family = "binomial")
p_penlog = t(predict(fit_penlog$glmnet.fit, newx = as.matrix(test_x), type = "response", s = fit_penlog$lambda.min))
rownames(p_penlog)="p_penlog"
p_results=rbind(p_results,p_penlog)
}
###Linear Discriminant Analysis
if(method[i] == "lda"){
fit_lda = lda(as.matrix(train_x), train_y)
p_lda = predict(fit_lda, as.matrix(test_x))$posterior[, 2]
p_results=rbind(p_results,p_lda)
}
###Sparse Linear Discriminant Analysis with LASSO penalty
if(method[i] == "slda"){
n1 = sum(train_y==1)
n0 = sum(train_y==0)
n = n1 + n0
y_lda = train_y
y_lda[train_y == 0] = -n/n0
y_lda[train_y == 1] = n/n1
fit_slda = cv.glmnet(as.matrix(train_x), y_lda)
score_slda = t(predict(fit_slda$glmnet.fit, newx = as.matrix(test_x), type = "link", s = fit_slda$lambda.min))
p_slda = 1/(1+exp(-score_slda))
rownames(p_slda)="p_slda"
p_results=rbind(p_results,p_slda)
}
###Naive Bayes
if(method[i] == "nb"){
train_data_nb = data.frame(train_x, y = train_y)
fit_nb <- naive_bayes(as.factor(y) ~ ., data = train_data_nb, usekernel = FALSE)
p_nb = predict(fit_nb, data.frame(test_x), type = "prob")[,2]
p_results=rbind(p_results,p_nb)
}
###Nonparametric Naive Bayes
if(method[i] == "nnb"){
train_data_nnb = data.frame(train_x, y = train_y)
fit_nnb <- naive_bayes(as.factor(y) ~ ., data = train_data_nnb, usekernel = TRUE)
p_nnb = predict(fit_nnb, data.frame(test_x), type = "prob")[,2]
p_results=rbind(p_results,p_nnb)
}
###Ada-Boost
if(method[i] == "ada"){
train_data_ada = data.frame(train_x, y = train_y)
fit_ada = ada(y ~ ., data = train_data_ada)
p_ada = predict(fit_ada, data.frame(test_x), type = "probs")[, 2]
p_results=rbind(p_results,p_ada)
}
###Classification
if(method[i] == "tree"){
# train_y = as.factor(train_y)
train_data_tree = data.frame(train_x, y = train_y)
fit_tree = tree(y~ ., data = train_data_tree)
p_tree = predict(fit_tree, newdata = data.frame(test_x), type = 'vector')
p_results=rbind(p_results,p_tree)
}
###Self-defined
if(method[i] == "self"){
p_self = func(train_x, train_y, test_x)
p_results=rbind(p_results,p_self)
}
}
p_results
View(p_results)
View(p_results)
library(SSD)
library(mvtnorm)
library(MASS)
df = 10
rho = 0.5
d = 5
delta = rep(2, d)
H <- abs(outer(1:d, 1:d, "-"))
covxx = rho^H
n1_all <- n0_all <- 800
n1_p <- n0_p <- 15
x0_all = rmvt(n = n0_all, sigma = covxx, delta = rep(0, d), df = df)
x1_all = rmvt(n = n1_all, sigma = covxx, delta = delta, df = df)
x_data = rbind(x0_all, x1_all)
y_data = c(rep(0, n0_all), rep(1, n1_all))
id0 <- which(y_data == 0)
id1 <- which(y_data == 1)
id0_p <- sample(id0, n0_p)
id1_p <- sample(id1, n1_p)
id_p <- c(id0_p, id1_p)
x_pilot <- as.matrix(x_data[id_p, ])
y_pilot <- as.matrix(y_data[id_p])
n1_train <- n0_train <- n_train <- 60
n0_test <- n1_test <- 300
result = pilot_tfe_smote(x_pilot, y_pilot, n0_train, n1_train, n0_test, n1_test,
method = c("svm", "randomforest")
)
View(result)
View(result)
calculate_AUCs
yeast_data <- read.table("./yeast.data")
###https://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set
x_data = yeast_data[,c(2:5,8:9)]
y_label = yeast_data[,10]
id0 = which(y_label=="CYT" | y_label=="MIT")
y_data = rep(1,length(y_label))
y_data[id0] = 0
table(y_data)
data = list(x_data=x_data, y_data=y_data)
calculate_AUCs(n01_p=c(15,15), n_train_sets = c(c(15,15),c(30,30),c(60,60),c(120,120),c(150,150)), n01_test=c(300,300), num_of_seeds=20, random_seeds=FALSE, calculate_std_of_AUC_and_produce_plot=TRUE, method="smote", model=c("svm","randomforest"), data_input=data)
calculate_AUCs(n01_all = c(800, 800), n01_p = c(15, 15),
n_train_sets = c(c(15, 15), c(30, 30), c(60, 60), c(120,
120), c(150, 150)), n01_test = c(300, 300), num_of_seeds = 20,
random_seeds = FALSE, calculate_std_of_AUC_and_produce_plot = TRUE, method="smote",
data_generation = list(dist = "t-distribution", sigma = list(class_0 = diag(5),
class_1 = diag(5)), df = c(10, 10), delta = c(rep(0,
5), rep(2, 5))))
library(mvtnorm)
library(MASS)
df = 10
rho = 0.5
d = 5
delta = rep(2, d)
H <- abs(outer(1:d, 1:d, "-"))
covxx = rho^H
n1_all <- n0_all <- 800
n1_train <- n0_train <- n_train <- 60
n0_test <- n1_test <- 300
x0_all = rmvt(n = n0_all, sigma = covxx, delta = rep(0, d), df = df)
x1_all = rmvt(n = n1_all, sigma = covxx, delta = delta, df = df)
x_data = rbind(x0_all, x1_all)
y_data = c(rep(0, n0_all), rep(1, n1_all))
id0 <- which(y_data == 0)
id1 <- which(y_data == 1)
id0_train <- sample(id0, n0_train)
id1_train <- sample(id1, n1_train)
id_train <- c(id0_train, id1_train)
x_train <- as.matrix(x_data[id_train, ])
y_train <- as.matrix(y_data[id_train])
id0_remain = setdiff(id0, id0_train)
id1_remain = setdiff(id1, id1_train)
id0_test <- sample(id0_remain, n0_test)
id1_test <- sample(id1_remain, n1_test)
id_test <- c(id0_test, id1_test)
x_test <- as.matrix(x_data[id_test, ])
result = pilot_train(x_train, y_train, x_test, method = c("svm", "randomforest"))
View(x_train)
View(x_train)
data_trainxy<-data.frame(x_train,y_train=as.factor(y_train))
View(data_trainxy)
View(data_trainxy)
colnames(x_train)
x_train
is.null(colnames(x_train))
if(is.null(colnames(x_train))){
cnames = paste("X",1:num_of_variables,sep="")
}else{
cnames = colnames(x_train)
}
num_of_variables = length(x_test[1,])
test_x=as.data.frame(x_test)
if(is.null(colnames(x_train))){
cnames = paste("X",1:num_of_variables,sep="")
}else{
cnames = colnames(x_train)
}
library(SSD)
library(mvtnorm)
library(MASS)
df = 10
rho = 0.5
d = 5
delta = rep(2, d)
H <- abs(outer(1:d, 1:d, "-"))
covxx = rho^H
n1_all <- n0_all <- 800
n1_train <- n0_train <- n_train <- 60
n0_test <- n1_test <- 300
x0_all = rmvt(n = n0_all, sigma = covxx, delta = rep(0, d), df = df)
x1_all = rmvt(n = n1_all, sigma = covxx, delta = delta, df = df)
x_data = rbind(x0_all, x1_all)
y_data = c(rep(0, n0_all), rep(1, n1_all))
id0 <- which(y_data == 0)
id1 <- which(y_data == 1)
id0_train <- sample(id0, n0_train)
id1_train <- sample(id1, n1_train)
id_train <- c(id0_train, id1_train)
x_train <- as.matrix(x_data[id_train, ])
y_train <- as.matrix(y_data[id_train])
id0_remain = setdiff(id0, id0_train)
id1_remain = setdiff(id1, id1_train)
id0_test <- sample(id0_remain, n0_test)
id1_test <- sample(id1_remain, n1_test)
id_test <- c(id0_test, id1_test)
x_test <- as.matrix(x_data[id_test, ])
result = pilot_train(x_train, y_train, x_test, method = c("svm", "randomforest"))
data_trainxy<-data.frame(x_train,y_train)
num_of_variables = length(x_test[1,])
test_x=as.data.frame(x_test)
if(is.null(colnames(x_train))){
cnames = paste("X",1:num_of_variables,sep="")
}else{
cnames = colnames(x_train)
}
colnames(test_x)=colnames(x_train)
test_x
cnames
library(SSD)
result = pilot_train(x_train, y_train, x_test, method = c("svm", "randomforest"))
calculate_AUCs(n01_all = c(800, 800), n01_p = c(15, 15),
n_train_sets = c(c(15, 15), c(30, 30), c(60, 60), c(120,
120), c(150, 150)), n01_test = c(300, 300), num_of_seeds = 20,
random_seeds = FALSE, calculate_std_of_AUC_and_produce_plot = TRUE, method="smote",
data_generation = list(dist = "t-distribution", sigma = list(class_0 = diag(5),
class_1 = diag(5)), df = c(10, 10), delta = c(rep(0,
5), rep(2, 5))))
load("C:/Users/ssd45/Dropbox/USC/RA/2020summer/R Package/Sample-Size-Determination/auc_res.Rdata")
View(res)
View(res)
res[[1]]
res[[3]]
library(SSD)
getwd()
calculate_AUCs(n01_all = c(800, 800), n01_p = c(15, 15),
n_train_sets = c(c(15, 15), c(30, 30), c(60, 60), c(120,
120), c(150, 150)), n01_test = c(300, 300), num_of_seeds = 20,
random_seeds = FALSE, calculate_std_of_AUC_and_produce_plot = TRUE,
data_generation = list(dist = "t-distribution", sigma = list(class_0 = diag(5),
class_1 = diag(5)), df = c(10, 10), delta = c(rep(0,
5), rep(2, 5))))
yeast_data <- read.table("./yeast.data")
###https://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set
x_data = yeast_data[,c(2:5,8:9)]
y_label = yeast_data[,10]
id0 = which(y_label=="CYT" | y_label=="MIT")
y_data = rep(1,length(y_label))
y_data[id0] = 0
table(y_data)
data = list(x_data=x_data, y_data=y_data)
calculate_AUCs(n01_p=c(15,15), n_train_sets = c(c(15,15),c(30,30),c(60,60),c(120,120),c(150,150)), n01_test=c(300,300), num_of_seeds=20, random_seeds=FALSE, calculate_std_of_AUC_and_produce_plot=TRUE, method="pca2_mvnorm", model=c("svm","randomforest"), data_input=data)
calculate_AUCs(n01_p=c(15,15), n_train_sets = c(c(15,15),c(30,30),c(60,60),c(120,120),c(150,150)), n01_test=c(300,300), num_of_seeds=20, random_seeds=FALSE, calculate_std_of_AUC_and_produce_plot=TRUE, method="smote", model=c("svm","randomforest"), data_input=data)
calculate_AUCs(n01_all = c(800, 800), n01_p = c(15, 15),
n_train_sets = c(c(15, 15), c(30, 30), c(60, 60), c(120,
120), c(150, 150)), n01_test = c(300, 300), num_of_seeds = 20,
random_seeds = FALSE, calculate_std_of_AUC_and_produce_plot = TRUE,
data_generation = list(dist = "t-distribution", sigma = list(class_0 = diag(5),
class_1 = diag(5)), df = c(10, 10), delta = c(rep(0,
5), rep(2, 5))), method = "smote")
calculate_AUCs(n01_all = c(800, 800), n01_p = c(15, 15),
n_train_sets = c(c(15, 15), c(30, 30), c(60, 60), c(120,
120), c(150, 150)), n01_test = c(300, 300), num_of_seeds = 20,
random_seeds = FALSE, calculate_std_of_AUC_and_produce_plot = TRUE,
data_generation = list(dist = "t-distribution", sigma = list(class_0 = diag(5),
class_1 = diag(5)), df = c(10, 10), delta = c(rep(0,
5), rep(2, 5))))
warnings()
getwd()
AUC = calculate_AUC_base(n01_all = c(800, 800), n01_p = c(15, 15), n01_test = c(300,
300), n_train_sets = c(c(15, 15), c(30, 30), c(60, 60), c(120, 120), c(150, 150)),
seed = 1, model = c("svm", "randomforest"), method="smote")
library(SSD)
install.packages("smotefamily")
library(SSD)
calculate_AUCs(n01_all = c(800, 800), n01_p = c(15, 15),
n_train_sets = c(c(15, 15), c(30, 30), c(60, 60), c(120,
120), c(150, 150)), n01_test = c(300, 300), num_of_seeds = 20,
random_seeds = FALSE, calculate_std_of_AUC_and_produce_plot = TRUE,
data_generation = list(dist = "t-distribution", sigma = list(class_0 = diag(5),
class_1 = diag(5)), df = c(10, 10), delta = c(rep(0,
5), rep(2, 5))), method="smote")
yeast_data <- read.table("./yeast.data")
###https://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set
x_data = yeast_data[,c(2:5,8:9)]
y_label = yeast_data[,10]
id0 = which(y_label=="CYT" | y_label=="MIT")
y_data = rep(1,length(y_label))
y_data[id0] = 0
table(y_data)
data = list(x_data=x_data, y_data=y_data)
calculate_AUCs(n01_p=c(15,15), n_train_sets = c(c(15,15),c(30,30),c(60,60),c(120,120),c(150,150)), n01_test=c(300,300), num_of_seeds=20, random_seeds=FALSE, calculate_std_of_AUC_and_produce_plot=TRUE, method="pca2_mvnorm", model=c("svm","randomforest"), data_input=data, method ="smote")
yeast_data <- read.table("./yeast.data")
###https://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set
x_data = yeast_data[,c(2:5,8:9)]
y_label = yeast_data[,10]
id0 = which(y_label=="CYT" | y_label=="MIT")
y_data = rep(1,length(y_label))
y_data[id0] = 0
table(y_data)
data = list(x_data=x_data, y_data=y_data)
calculate_AUCs(n01_p=c(15,15), n_train_sets = c(c(15,15),c(30,30),c(60,60),c(120,120),c(150,150)), n01_test=c(300,300), num_of_seeds=20, random_seeds=FALSE, calculate_std_of_AUC_and_produce_plot=TRUE, method="smote", model=c("svm","randomforest"), data_input=data)
load("D:/Dropbox/USC/RA/2020summer/R Package/Sample-Size-Determination/auc_res_smote_def.Rdata")
View(res)
AUC = calculate_AUC_base(n01_p=c(15,15), n_train_sets = c(c(15,15),c(30,30),c(60,60),c(120,120),c(150,150)), n01_test=c(300,300), seed=1, method="pca2_mvnorm", model=c("svm","randomforest"), data_input=data)
AUC_s = calculate_AUC_base(n01_p=c(15,15), n_train_sets = c(c(15,15),c(30,30),c(60,60),c(120,120),c(150,150)), n01_test=c(300,300), seed=1, method="smote", model=c("svm","randomforest"), data_input=data)
AUC
AUC_s
calculate_AUCs(n01_p=c(15,15), n_train_sets = c(c(15,15),c(30,30),c(60,60),c(120,120),c(150,150)), n01_test=c(300,300), num_of_seeds=20, random_seeds=FALSE, calculate_std_of_AUC_and_produce_plot=TRUE, method="smote", model=c("svm","randomforest"), data_input=data)
